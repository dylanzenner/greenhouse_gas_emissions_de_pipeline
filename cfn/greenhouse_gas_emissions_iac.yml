AWSTemplateFormatVersion: '2010-09-09'
Description: "This template launches all the necessary resources required for the SF Greenhouse Gas Emissions DE Pipeline Project"
Parameters:

# Alarm email for SNS
  AlarmEmail:
    Default: # Your email here
    Description: "email address to notify us of operational issues"
    Type: "String"

# Resources section
Resources:

# VPC for the project
  VPC:
   Type: 'AWS::EC2::VPC'
   Properties:
     CidrBlock: 10.0.0.0/20
     Tags:
       - Key: name
         Value: DE-Project2-VPC

# Internet Gateway for VPC
  IGW:
    Type: 'AWS::EC2::InternetGateway'
    Properties:
      Tags:
        - Key: name
          Value: DE-Project2-IGW

# NatGateway for public subnet
  NATGW:
    Type: 'AWS::EC2::NatGateway'
    Properties:
      AllocationId:
        'Fn::GetAtt':
          - EIP
          - AllocationId
      SubnetId: !Ref PublicSubnet

# Elastic IP address for the NatGateway
  EIP:
    Type: 'AWS::EC2::EIP'
    DependsOn: VPCGatewayAttachment
    Properties:
      Domain: VPC
      Tags:
        - Key: name
          Value: DE-Project2-NATGW-EIP

# Gateway attachment to allow VPC internet access
  VPCGatewayAttachment:
    Type: 'AWS::EC2::VPCGatewayAttachment'
    Properties:
      InternetGatewayId: !Ref IGW
      VpcId: !Ref VPC

# Public Subnet
  PublicSubnet:
    Type: 'AWS::EC2::Subnet'
    Properties:
      CidrBlock: 10.0.0.0/22
      AvailabilityZone: us-east-1a
      VpcId: !Ref VPC
      Tags:
        - Key: name
          Value: DE-Project2-Public-Subnet

# Private Subnet
  PrivateSubnet:
    Type: 'AWS::EC2::Subnet'
    Properties:
      CidrBlock: 10.0.4.0/22
      AvailabilityZone: us-east-1b
      VpcId: !Ref VPC
      Tags:
        - Key: name
          Value: DE-Project2-Private-Subnet

# Public Route Table
  PublicRouteTable:
    Type: 'AWS::EC2::RouteTable'
    Properties:
      VpcId: !Ref VPC
      Tags:
        - Key: name
          Value: DE-Project2-Public-Route-Table

# Internet Gateway route to the public route table
  PublicIGWRoute:
    Type: 'AWS::EC2::Route'
    DependsOn: VPCGatewayAttachment
    Properties:
      RouteTableId: !Ref PublicRouteTable
      DestinationCidrBlock: 0.0.0.0/0
      GatewayId: !Ref IGW

# Route table association for the public subnet
  PublicRouteTableAssociation:
    Type: 'AWS::EC2::SubnetRouteTableAssociation'
    Properties:
      RouteTableId: !Ref PublicRouteTable
      SubnetId: !Ref PublicSubnet

# Private route table
  PrivateRouteTable:
    Type: 'AWS::EC2::RouteTable'
    Properties:
      VpcId: !Ref VPC
      Tags:
        - Key: name
          Value: DE-Project2-Private-Route-Table

# NatGateway route to the private route table
  NATGWRoute:
    Type: 'AWS::EC2::Route'
    Properties:
      RouteTableId: !Ref PrivateRouteTable
      DestinationCidrBlock: 0.0.0.0/0
      NatGatewayId: !Ref NATGW

# Route table association for the private subnet
  PrivateRouteTableAssociation:
    Type: 'AWS::EC2::SubnetRouteTableAssociation'
    Properties:
      RouteTableId: !Ref PrivateRouteTable
      SubnetId: !Ref PrivateSubnet

# Lambda function which pulls data from the API and sends it to an SQS queue for processing
  LambdaFunction1:
    Type: 'AWS::Lambda::Function'
    Properties:
      Code:
        S3Bucket: greenhouse-gas-emissions
        S3Key: pull_data.zip
      Description: 'Pulls Data from source API'
      FunctionName: 'pull_data'
      Handler: 'pull_data.lambda_handler'
      MemorySize: 500
      PackageType: 'Zip'
      Role: # Your lambda function role here
      Runtime: 'python3.8'
      Timeout: 300
      VpcConfig:
        SecurityGroupIds:
          - !Ref LambdaSecurityGroup
        SubnetIds:
          - !Ref PrivateSubnet

# Lambda function which processes the data in the SQS queue and sends it to DynamoDB
  LambdaFunction2:
    Type: 'AWS::Lambda::Function'
    Properties:
      Code:
        S3Bucket: greenhouse-gas-emissions
        S3Key: send_to_dynamodb.py.zip
      Description: 'Transforms data from the sqs queue and sends it to DynamoDB'
      FunctionName: 'send_to_dynamodb'
      Handler: 'send_to_dynamodb.lambda_handler'
      MemorySize: 500
      PackageType: 'Zip'
      Role: # Your lambda function role here
      Runtime: 'python3.8'
      Timeout: 30
      VpcConfig:
        SecurityGroupIds:
          - !Ref LambdaSecurityGroup
        SubnetIds:
          - !Ref PrivateSubnet

# Lambda function which initiates the DynamoDB export to S3
  LambdaFunction3:
    Type: 'AWS::Lambda::Function'
    Properties:
      Code:
        S3Bucket: greenhouse-gas-emissions
        S3Key: export_to_s3.py.zip
      Description: 'Exports the data from DynamoDb to an S3 Bucket'
      FunctionName: 'export_to_s3'
      Handler: 'export_to_s3.lambda_handler'
      MemorySize: 500
      PackageType: 'Zip'
      Role: # Your lambda function role here
      Runtime: 'python3.8'
      Timeout: 600
      VpcConfig:
        SecurityGroupIds:
          - !Ref LambdaSecurityGroup
        SubnetIds:
          - !Ref PrivateSubnet

# The security group for the lambda functions
  LambdaSecurityGroup:
    Type: 'AWS::EC2::SecurityGroup'
    Properties:
      GroupDescription: 'Gives the Lambda functions permission to pull data'
      GroupName: 'Lambda1SecurityGroup'
      SecurityGroupEgress:
        - CidrIp: 0.0.0.0/0
          IpProtocol: '-1'
      VpcId: !Ref VPC

# SQS trigger to initiate the second lambda function when a message is sent to the SQS queue
  LambdaSQSTrigger:
    Type: "AWS::Lambda::EventSourceMapping"
    Properties:
      BatchSize: 1
      EventSourceArn:
        Fn::GetAtt:
          - "SQSQueue"
          - "Arn"
      FunctionName: !Ref LambdaFunction2

# SQS Dead-Letter queue trigger for invoking a lambda to process the messages
  DeadLetterSQSTrigger:
    Type: "AWS::Lambda::EventSourceMapping"
    Properties:
      BatchSize: 1
      EventSourceArn:
        Fn::GetAtt:
          - "DeadLetterQueue"
          - "Arn"
      FunctionName: !Ref LambdaFunction2

# DynamoDB table which stores the processed data
  DynamoDBTable1:
    Type: "AWS::DynamoDB::Table"
    Properties:
      AttributeDefinitions:
        -
          AttributeName: "id"
          AttributeType: "B"
      KeySchema:
        -
          AttributeName: "id"
          KeyType: "HASH"
      BillingMode: "PAY_PER_REQUEST"
      TableName: "Greenhouse_gas_emissions"

# SQS queue which the raw API data is sent to
  SQSQueue:
    Type: "AWS::SQS::Queue"
    Properties:
      QueueName: "greenhouse_gas_emissions"
      ReceiveMessageWaitTimeSeconds: 20
      VisibilityTimeout: 30
      RedrivePolicy:
        deadLetterTargetArn:
          Fn::GetAtt:
            - "DeadLetterQueue"
            - "Arn"
        maxReceiveCount: 10

# Dead-Letter Queue for retrying failed messages
  DeadLetterQueue:
    Type: "AWS::SQS::Queue"
    Properties:
      QueueName: "dead-letter-queue"

# SNS Alarm topic for sqs
  SNSAlarmTopic:
    Type: "AWS::SNS::Topic"
    Properties:
      DisplayName: "sqs_alarm"
      Subscription:
        -
          Endpoint: !Ref AlarmEmail
          Protocol: "email"

# SQS queue alarm
  QueueDepthAlarm:
    Type: "AWS::CloudWatch::Alarm"
    Properties:
      AlarmActions:
        -
          Ref: "SNSAlarmTopic"
      AlarmDescription: "Alarm if queue depth increases to more than 10 messages"
      ComparisonOperator: "GreaterThanThreshold"
      Namespace: "AWS/SQS"
      MetricName: "ApproximateNumberOfMessagesVisible"
      InsufficientDataActions:
        -
          Ref: "SNSAlarmTopic"
      Statistic: "Sum"
      Period: 300
      EvaluationPeriods: 1
      Threshold: 10
      Dimensions:
        - Name: "QueueName"
          Value: !Ref SQSQueue

# ARN of the DynamoDB table
  TableARNSecretsManager:
    Type: "AWS::SecretsManager::Secret"
    Properties:
      Description: "Creates and stores the DynamoDB table ARN in SecretsManager"
      Name: "dynamodb_arn"
      SecretString:
        Fn::GetAtt:
          - "DynamoDBTable1"
          - "Arn"

# CW TBE for starting the pipeline
  StartPipelineCWTBE:
    Type: "AWS::Events::Rule"
    Properties:
      Description: "A CW Time-Based event that starts the DE Pipeline"
      Name: "Start-Pipeline"
      ScheduleExpression: "rate(30 days)"
      State: "ENABLED"
      Targets:
        -
          Arn:
            Fn::GetAtt:
              - "LambdaFunction1"
              - "Arn"
          Id: "TargetFunctionV1"

# CW TBE for exporting the data from DynamoDB to S3
  ExportDataToS3CWTBE:
    Type: "AWS::Events::Rule"
    Properties:
      Description: "A CW Time-Based event that invokes a lambda function to export the data from DDynamoDB to S3"
      Name: "Export-Data-From-DynamoDB"
      ScheduleExpression: "rate(31 days)"
      State: "ENABLED"
      Targets:
        -
          Arn:
            Fn::GetAtt:
              - "LambdaFunction3"
              - "Arn"
          Id: "TargetFunctionV1"

# Outputs section
Outputs:

# SQS Queue URL
  QueueURL:
    Description: "URL of SQS Queue"
    Value: !Ref SQSQueue

# SQS Queue ARN
  QueueARN:
    Description: "ARN of new AmazonSQS Queue"
    Value:
      Fn::GetAtt:
        - "SQSQueue"
        - "Arn"

# SQS Queue Name
  QueueName:
    Description: "Name of new SQS Queue"
    Value:
      Fn::GetAtt:
        - "SQSQueue"
        - "QueueName"

# SQS Dead-Letter Queue URL
  DeadLetterQueueURL:
    Description: "URL of dead-letter queue"
    Value:
      Ref: "DeadLetterQueue"

# SQS Dead-Letter Queue ARN
  DeadLetterQueueARN:
    Description: "ARN of dead-letter queue"
    Value:
      Fn::GetAtt:
        - "DeadLetterQueue"
        - "Arn"
